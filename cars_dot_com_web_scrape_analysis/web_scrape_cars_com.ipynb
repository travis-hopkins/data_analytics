{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f71c227-82ce-43e8-a476-251ddb77c26f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping car info from: https://www.cars.com/shopping/atlanta-ga/?page=1\n",
      "Scraping car info from: https://www.cars.com/shopping/atlanta-ga/?page=2\n",
      "Scraping car info from: https://www.cars.com/shopping/atlanta-ga/?page=3\n",
      "Scraping car info from: https://www.cars.com/shopping/atlanta-ga/?page=4\n",
      "Scraping car info from: https://www.cars.com/shopping/atlanta-ga/?page=5\n",
      "Scraping car info from: https://www.cars.com/shopping/atlanta-ga/?page=6\n",
      "Scraping car info from: https://www.cars.com/shopping/atlanta-ga/?page=7\n",
      "Scraping car info from: https://www.cars.com/shopping/atlanta-ga/?page=8\n",
      "Scraping car info from: https://www.cars.com/shopping/atlanta-ga/?page=9\n",
      "Scraping car info from: https://www.cars.com/shopping/atlanta-ga/?page=10\n",
      "Scraping car info from: https://www.cars.com/shopping/chicago-il/?page=1\n",
      "Scraping car info from: https://www.cars.com/shopping/chicago-il/?page=2\n",
      "Scraping car info from: https://www.cars.com/shopping/chicago-il/?page=3\n",
      "Scraping car info from: https://www.cars.com/shopping/chicago-il/?page=4\n",
      "Scraping car info from: https://www.cars.com/shopping/chicago-il/?page=5\n",
      "Scraping car info from: https://www.cars.com/shopping/chicago-il/?page=6\n",
      "Scraping car info from: https://www.cars.com/shopping/chicago-il/?page=7\n",
      "Scraping car info from: https://www.cars.com/shopping/chicago-il/?page=8\n",
      "Scraping car info from: https://www.cars.com/shopping/chicago-il/?page=9\n",
      "Scraping car info from: https://www.cars.com/shopping/chicago-il/?page=10\n",
      "Scraping car info from: https://www.cars.com/shopping/columbus-oh/?page=1\n",
      "Scraping car info from: https://www.cars.com/shopping/columbus-oh/?page=2\n",
      "Scraping car info from: https://www.cars.com/shopping/columbus-oh/?page=3\n",
      "Scraping car info from: https://www.cars.com/shopping/columbus-oh/?page=4\n",
      "Scraping car info from: https://www.cars.com/shopping/columbus-oh/?page=5\n",
      "Scraping car info from: https://www.cars.com/shopping/columbus-oh/?page=6\n",
      "Scraping car info from: https://www.cars.com/shopping/columbus-oh/?page=7\n",
      "Scraping car info from: https://www.cars.com/shopping/columbus-oh/?page=8\n",
      "Scraping car info from: https://www.cars.com/shopping/columbus-oh/?page=9\n",
      "Scraping car info from: https://www.cars.com/shopping/columbus-oh/?page=10\n",
      "Scraping car info from: https://www.cars.com/shopping/dallas-tx/?page=1\n",
      "Scraping car info from: https://www.cars.com/shopping/dallas-tx/?page=2\n",
      "Scraping car info from: https://www.cars.com/shopping/dallas-tx/?page=3\n",
      "Scraping car info from: https://www.cars.com/shopping/dallas-tx/?page=4\n",
      "Scraping car info from: https://www.cars.com/shopping/dallas-tx/?page=5\n",
      "Scraping car info from: https://www.cars.com/shopping/dallas-tx/?page=6\n",
      "Scraping car info from: https://www.cars.com/shopping/dallas-tx/?page=7\n",
      "Scraping car info from: https://www.cars.com/shopping/dallas-tx/?page=8\n",
      "Scraping car info from: https://www.cars.com/shopping/dallas-tx/?page=9\n",
      "Scraping car info from: https://www.cars.com/shopping/dallas-tx/?page=10\n",
      "Scraping car info from: https://www.cars.com/shopping/denver-co/?page=1\n",
      "Scraping car info from: https://www.cars.com/shopping/denver-co/?page=2\n",
      "Scraping car info from: https://www.cars.com/shopping/denver-co/?page=3\n",
      "Scraping car info from: https://www.cars.com/shopping/denver-co/?page=4\n",
      "Scraping car info from: https://www.cars.com/shopping/denver-co/?page=5\n",
      "Scraping car info from: https://www.cars.com/shopping/denver-co/?page=6\n",
      "Scraping car info from: https://www.cars.com/shopping/denver-co/?page=7\n",
      "Scraping car info from: https://www.cars.com/shopping/denver-co/?page=8\n",
      "Scraping car info from: https://www.cars.com/shopping/denver-co/?page=9\n",
      "Scraping car info from: https://www.cars.com/shopping/denver-co/?page=10\n",
      "Scraping car info from: https://www.cars.com/shopping/houston-tx/?page=1\n",
      "Scraping car info from: https://www.cars.com/shopping/houston-tx/?page=2\n",
      "Scraping car info from: https://www.cars.com/shopping/houston-tx/?page=3\n",
      "Scraping car info from: https://www.cars.com/shopping/houston-tx/?page=4\n",
      "Scraping car info from: https://www.cars.com/shopping/houston-tx/?page=5\n",
      "Scraping car info from: https://www.cars.com/shopping/houston-tx/?page=6\n",
      "Scraping car info from: https://www.cars.com/shopping/houston-tx/?page=7\n",
      "Scraping car info from: https://www.cars.com/shopping/houston-tx/?page=8\n",
      "Scraping car info from: https://www.cars.com/shopping/houston-tx/?page=9\n",
      "Scraping car info from: https://www.cars.com/shopping/houston-tx/?page=10\n",
      "Scraping car info from: https://www.cars.com/shopping/los-angeles-ca/?page=1\n",
      "No car listings found on this page.\n",
      "Scraping car info from: https://www.cars.com/shopping/new-york-ny/?page=1\n",
      "No car listings found on this page.\n",
      "Scraping car info from: https://www.cars.com/shopping/philadelphia-pa/?page=1\n",
      "Scraping car info from: https://www.cars.com/shopping/philadelphia-pa/?page=2\n",
      "Scraping car info from: https://www.cars.com/shopping/philadelphia-pa/?page=3\n",
      "Scraping car info from: https://www.cars.com/shopping/philadelphia-pa/?page=4\n",
      "Scraping car info from: https://www.cars.com/shopping/philadelphia-pa/?page=5\n",
      "Scraping car info from: https://www.cars.com/shopping/philadelphia-pa/?page=6\n",
      "Scraping car info from: https://www.cars.com/shopping/philadelphia-pa/?page=7\n",
      "Scraping car info from: https://www.cars.com/shopping/philadelphia-pa/?page=8\n",
      "Scraping car info from: https://www.cars.com/shopping/philadelphia-pa/?page=9\n",
      "Scraping car info from: https://www.cars.com/shopping/philadelphia-pa/?page=10\n",
      "Scraping car info from: https://www.cars.com/shopping/phoenix-az/?page=1\n",
      "Scraping car info from: https://www.cars.com/shopping/phoenix-az/?page=2\n",
      "Scraping car info from: https://www.cars.com/shopping/phoenix-az/?page=3\n",
      "Scraping car info from: https://www.cars.com/shopping/phoenix-az/?page=4\n",
      "Scraping car info from: https://www.cars.com/shopping/phoenix-az/?page=5\n",
      "Scraping car info from: https://www.cars.com/shopping/phoenix-az/?page=6\n",
      "Scraping car info from: https://www.cars.com/shopping/phoenix-az/?page=7\n",
      "Scraping car info from: https://www.cars.com/shopping/phoenix-az/?page=8\n",
      "Scraping car info from: https://www.cars.com/shopping/phoenix-az/?page=9\n",
      "Scraping car info from: https://www.cars.com/shopping/phoenix-az/?page=10\n",
      "Scraping car info from: https://www.cars.com/shopping/san-diego-ca/?page=1\n",
      "No car listings found on this page.\n",
      "Scraping car info from: https://www.cars.com/shopping/seattle-wa/?page=1\n",
      "Scraping car info from: https://www.cars.com/shopping/seattle-wa/?page=2\n",
      "Scraping car info from: https://www.cars.com/shopping/seattle-wa/?page=3\n",
      "Scraping car info from: https://www.cars.com/shopping/seattle-wa/?page=4\n",
      "Scraping car info from: https://www.cars.com/shopping/seattle-wa/?page=5\n",
      "Scraping car info from: https://www.cars.com/shopping/seattle-wa/?page=6\n",
      "Scraping car info from: https://www.cars.com/shopping/seattle-wa/?page=7\n",
      "Scraping car info from: https://www.cars.com/shopping/seattle-wa/?page=8\n",
      "Scraping car info from: https://www.cars.com/shopping/seattle-wa/?page=9\n",
      "Scraping car info from: https://www.cars.com/shopping/seattle-wa/?page=10\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Grab all vehicles on each location's vehicle page\n",
    "def scrape_car_info(url, location):\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'Accept-Encoding': 'gzip, deflate, br',\n",
    "            'Connection': 'keep-alive'\n",
    "        }\n",
    "        print(\"Scraping car info from:\", url)\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            #print(\"Successfully connected to:\", url) For debugging\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            car_listings = soup.find_all(\"a\", href=re.compile(\"^/vehicledetail/\"))\n",
    "            if not car_listings:\n",
    "                print(\"No car listings found on this page.\")\n",
    "                return None\n",
    "            car_data = []\n",
    "            for car_link in car_listings:\n",
    "                car_url = \"https://www.cars.com\" + car_link['href']\n",
    "                # print(\"Found car detail URL:\", car_url) For debugging\n",
    "                car_details = scrape_car_details(car_url, location)\n",
    "                if car_details:\n",
    "                    car_data.append(car_details)\n",
    "            return car_data\n",
    "        else:\n",
    "            print(f\"Failed to connect to: {url}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        return None\n",
    "        \n",
    "# Parse each individual vehicle's detail page for data\n",
    "def scrape_car_details(url, location):\n",
    "    try:\n",
    "       # print(\"Parsing car details:\", URL) For debugging\n",
    "        if url in parsed_urls:\n",
    "            #print(\"URL already parsed. Skipping...\")\n",
    "            return None\n",
    "        \n",
    "        parsed_urls.add(url)  # Add the URL to the list of parsed URLs\n",
    "        \n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'Accept-Encoding': 'gzip, deflate, br',\n",
    "            'Connection': 'keep-alive'\n",
    "        }\n",
    "        \n",
    "        # print(\"Attempting to get response from:\", url)  # New debug print\n",
    "        response = requests.get(url, headers=headers)\n",
    "        # print(\"Response status code:\", response.status_code)  # Debug print\n",
    "        if response.status_code == 200:\n",
    "           # print(\"Successfully connected to:\", url) For debugging\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "            # Find elements\n",
    "            exterior_color_element = soup.find(\"dt\", string=\"Exterior color\")\n",
    "            interior_color_element = soup.find(\"dt\", string=\"Interior color\")\n",
    "            drive_train_element = soup.find(\"dt\", string=\"Drivetrain\")\n",
    "            mpg_element = soup.find(\"dt\", string=\"MPG\")\n",
    "            fuel_type_element = soup.find(\"dt\", string=\"Fuel type\")\n",
    "            transmission_element = soup.find(\"dt\", string=\"Transmission\")\n",
    "            engine_element = soup.find(\"dt\", string=\"Engine\")\n",
    "            mileage_element = soup.find(\"dt\", string=\"Mileage\")\n",
    "            status_element = soup.find(\"p\", class_=\"new-used\")  # New element\n",
    "            title_element = soup.find(\"h1\", class_=\"listing-title\")  # New element\n",
    "\n",
    "            # Extract text from elements\n",
    "            exterior_color = exterior_color_element.find_next(\"dd\").text.strip() if exterior_color_element else None\n",
    "            interior_color = interior_color_element.find_next(\"dd\").text.strip() if interior_color_element else None\n",
    "            drive_train = drive_train_element.find_next(\"dd\").text.strip() if drive_train_element else None\n",
    "            mpg_text = mpg_element.find_next(\"dd\").text.strip() if mpg_element else None\n",
    "            mpg = \"-\".join(re.findall(r'\\b\\d+-?\\d*\\b', mpg_text)) if mpg_text else 'NULL'\n",
    "            fuel_type = fuel_type_element.find_next(\"dd\").text.strip() if fuel_type_element else None\n",
    "            transmission = transmission_element.find_next(\"dd\").text.strip() if transmission_element else None\n",
    "            engine = engine_element.find_next(\"dd\").text.strip() if engine_element else None\n",
    "            mileage = mileage_element.find_next(\"dd\").text.strip() if mileage_element else None\n",
    "            status = status_element.text.strip() if status_element else None  # Extract status\n",
    "            title = title_element.text.strip() if title_element else None  # Extract title\n",
    "\n",
    "            # Extract year, brand, and model from title\n",
    "            year = None\n",
    "            brand = None\n",
    "            model = None\n",
    "            if title:\n",
    "                title_parts = title.split()\n",
    "                year = title_parts[0] if title_parts else None\n",
    "                brand = title_parts[1] if len(title_parts) > 1 else None\n",
    "                model = \" \".join(title_parts[2:]) if len(title_parts) > 2 else None\n",
    "\n",
    "            # Print parsed data for debugging\n",
    "            # print(\"Parsed car details:\")\n",
    "            # print(\"Location:\", location)\n",
    "            # print(\"Exterior Color:\", exterior_color)\n",
    "            # print(\"Interior Color:\", interior_color)\n",
    "            # print(\"Drive Train:\", drive_train)\n",
    "            # print(\"MPG:\", mpg)\n",
    "            # print(\"Fuel Type:\", fuel_type)\n",
    "            # print(\"Transmission:\", transmission)\n",
    "            # print(\"Engine:\", engine)\n",
    "            # print(\"Mileage:\", mileage)\n",
    "            # print(\"Status:\", status)\n",
    "            # print(\"Year:\", year)\n",
    "            # print(\"Brand:\", brand)\n",
    "            # print(\"Model:\", model)\n",
    "\n",
    "            return {\n",
    "                \"Location\": location,\n",
    "                \"Exterior_Color\": exterior_color,\n",
    "                \"Interior_Color\": interior_color,\n",
    "                \"Drive_Train\": drive_train,\n",
    "                \"MPG\": mpg,\n",
    "                \"Fuel_Type\": fuel_type,\n",
    "                \"Transmission\": transmission,\n",
    "                \"Engine\": engine,\n",
    "                \"Mileage\": mileage,\n",
    "                \"Status\": status,\n",
    "                \"Year\": year,\n",
    "                \"Brand\": brand,\n",
    "                \"Model\": model\n",
    "            }\n",
    "        else:\n",
    "            print(f\"Failed to connect to: {url}\")\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "\n",
    "# List of locations to scrape\n",
    "locations = [\n",
    "    \"atlanta-ga\",\n",
    "    \"chicago-il\",\n",
    "    \"columbus-oh\",\n",
    "    \"dallas-tx\",\n",
    "    \"denver-co\",\n",
    "    \"houston-tx\",\n",
    "    \"los-angeles-ca\",\n",
    "    \"new-york-ny\",\n",
    "    \"philadelphia-pa\",\n",
    "    \"phoenix-az\",\n",
    "    \"san_diego-ca\",\n",
    "    \"seattle-wa\"\n",
    "]\n",
    "\n",
    "# Set to keep track of parsed URLs\n",
    "parsed_urls = set()\n",
    "\n",
    "# Set the maximum number of pages to scrape for each location\n",
    "max_pages = 10\n",
    "\n",
    "all_car_data = []  # List to store data for all locations\n",
    "\n",
    "for location in locations:\n",
    "    page_count = 1\n",
    "    while page_count <= max_pages:\n",
    "        url = f\"https://www.cars.com/shopping/{location}/?page={page_count}\"\n",
    "        car_data = scrape_car_info(url, location)\n",
    "        if not car_data:\n",
    "            break\n",
    "        all_car_data.extend(car_data)\n",
    "        page_count += 1\n",
    "\n",
    "# Convert data to DataFrame\n",
    "df = pd.DataFrame(all_car_data)\n",
    "\n",
    "# Save DataFrame to CSV\n",
    "df.to_csv(\"cars_by_popular_city.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4c731c-85ee-4a34-9a6a-15f9ab22a81a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
